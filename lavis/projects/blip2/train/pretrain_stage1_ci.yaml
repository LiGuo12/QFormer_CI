 # Copyright (c) 2024, Li Guo
 # All rights reserved.
 
model:
  arch: blip2_ci
  model_type: pretrain
  max_txt_len: 60
  load_pretrained: False
  freeze_vit: True
  pretrained_Qformer: "Path/to/checkpoint.pth"
  num_query_token: 64
  medical_mae_vit_b: "Path/to/vit-b_CXR_0.5M_mae.pth"
  top_k_tokens: 6 # select top 6 patch tokens for each head

datasets:
  iu_xray:
    data_type: images
    build_info:
      compressed_features:
        storage: "Path/to/features_compressed.h5"
      annotations:
        train:
          storage: 'Path/to/annotation.json'
        val:
          storage: 'Path/to/annotation.json'
        test:
          storage: 'Path/to/annotation.json'
      images:
        storage: 'Path/to/images'
    vis_processor:
      train:
        name: "blip2_image_train_cxr"
        
        image_size: 224
      eval:
        name: "blip_image_eval"
        image_size: 224
    text_processor:
      train:
        name: "medical_report_processor"
      eval:
        name: "medical_report_processor"

run:
  task: image_text_pretrain_ce
  # optimizer
  lr_sched: "linear_warmup_cosine_lr"
  init_lr: 1e-4
  min_lr: 1e-5
  warmup_lr: 1e-6

  weight_decay: 0.05
  max_epoch: 100 
  batch_size_train: 64
  batch_size_eval: 16 
  num_workers: 4 
  warmup_steps: 5000 

  seed: 42
  output_dir: "output/BLIP2/Pretrain_stage1"

  amp: True
  resume_ckpt_path: null

  evaluate: True
  train_splits: ["train"]
  valid_splits: ["val"]
  test_splits: ["test"]

  device: "cuda"
  world_size: 1
  dist_url: "env://"
  distributed: True 
  

  max_len: 60
  min_len: 10
  num_beams: 5
